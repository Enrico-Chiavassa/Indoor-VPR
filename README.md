# Indoor-VPR
This repo contains VPR models that have been fine-tuned for indoor usage.
Currently available models come from the following repositories:
- [EigenPlaces: Training Viewpoint Robust Models for Visual Place Recognition](https://github.com/gmberton/EigenPlaces);
- [Optimal Transport Aggregation for Visual Place Recognition (Salad)](https://github.com/serizba/salad).

The fine-tuned procedure is inspired by [Deep Visual Geo-localization Benchmark](https://github.com/gmberton/deep-visual-geo-localization-benchmark)

The indoor datasets used for fine-tuning are:
 - [Gangnam Station B1-B2 and Hyundai Department Store B1-1F-4F](https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Large-Scale_Localization_Datasets_in_Crowded_Indoor_Spaces_CVPR_2021_paper.pdf);
 - [Baidu Mall](https://openaccess.thecvf.com/content_cvpr_2017/html/Sun_A_Dataset_for_CVPR_2017_paper.html).

